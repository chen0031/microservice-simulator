:toc:
:toc-placement!:

:note-caption: :information_source:
:tip-caption: :bulb:
:important-caption: :heavy_exclamation_mark:
:warning-caption: :warning:
:caution-caption: :fire:

= Guidebook
Ron Kurr <rkurr@jvmguy.com>

toc::[]

== Context
This system makes it easy to simulate a solution comprised of many microservices, allowing the testing of the operational aspects of the system, such as the information provided by distributed tracing or the scheduler's ability to self-heal.  The project provides the scripts and containers needed to create the system, either locally or in the Amazon cloud.  The project is meant to be a standalone experiment and does not fit into any existing production environments.

[CAUTION]
.Nerd Speak
===========
Blah, blah, blah.
===========

.Context Diagram
image::images/context-diagram.png[Context Diagram]

== Functional Overview
The system is conceptually very simple.  A simulated client will introduce a request into the system, asking for a "question" to be answered.  The request enters into the system and cascades throughout the back end containers  eventually returning the result back to the client.  The client can make requests either through messaging or REST, allowing us to test the two forms of communication.  A very simple control plane is used to alter the behavior of the various containers as the system runs, such as introducing latency or failing health checks, allowing the Operator to run a variety of tests.  The payloads, as they traverse the system, are constructed in such a way so as to provide a "trail" of how the services had to be coordinated in order to fulfill the request.  The Operator has the option of constructing either a wide, shallow system or a narrow, deep one, observing how differently the system behaves with each configuration.

.Sequence Diagram
image::images/sequence-diagram.png[Sequence Diagram]

== Quality Attributes
The latency and throughput values are controlled by Operator, depending on the experiment being run.  Delays can be introduced into the containers to increase latency.  The Operator also has the option of using sequential or parallel communication algorithms to affect throughput.  Scalability and availability can be controlled by the Operator via the container scheduler being used.  To keep the implementation simple, no security protocols are part of the simulation.  When running in the Amazon cloud, native AWS monitoring and tracing solutions are used.  When running in a development environment, open source equivalents are used.

== Constraints

. Technology For Each Context
[options="header"]
|=======
|Technology          |Amazon          |Local
|Distributed tracing |X-Ray           |Zipkin
|Distributed logging |CloudWatch Logs |Elastic Stack
|Scheduler           |ECS Fargate     |Swarm
|Message Schema      |Avro JSON       |Avro JSON
|Messaging Protocol  |AMQP            |AMQP
|Reactive Stack      |Reactor         |Reactor
|OS                  |Amazon Linux    |Amazon Linux
|Provisioner         |Terraform       |Ansible
|=======

== Principles
. prefer containerized solutions
. prefer automation

== Software Architecture
. Summarize the software architecture
. What does the "big picture" look like?
. Is there a clear structure?
. Is it clear how the system works from the "30,000 foot view"?
. Does it show major containers and technology choices?
. Does it show major components and their interactions?
. What are the key internal interfaces? (e.g. web service between web and business tiers)
. Technical people only

== External Interfaces
. What are the key external interfaces?
.. system-to-system
.. publicly exposed APIs
.. exported files
. Has each interface been thought about from a technical perspective?
.. what is the technical definition of an interface?
.. if messaging is being used, which queues and topics are components using to communicate?
.. what format are the messages (e.g. plain text, Avro, JSON)?
.. are they synchronous or asynchronous?
.. are asynchronous messaging links guaranteed?
.. are subscribers durable where necessary?
.. can messages be received out of order and is this a problem?
.. are interfaces idempotent?
.. is the interface always available or do you need the cache data locally?
.. how is performance/security/etc catered for?
. Has each interface been thought about from a non-technical perspective?
.. who has ownership of the interface?
.. how often does the interface change and how is versioning handled?
.. are there service-level agreements in place?
. A paragraph on each interface covering this topics is sufficient
. Technical people only

== Code
=== Dynamic Routing Logic
We need a mechanism that allows the Operator to configure different message routes using the same set of components so different system tests can be performed.  The *Recipient List* pattern, in combination with AMQP's Headers Exchange, is a good fit for this problem.  https://www.cloudamqp.com/blog/2015-09-03-part4-rabbitmq-for-beginners-exchanges-routing-keys-bindings.html[Headers Exchange] is used to route messages to the proper consumers based on the values of AMQP headers.

.Headers Used For Routing
. *Message Type* -- can be either *Command* or *Event*
. *Subject* -- the *what* or *whom* the message is about, e.g. *user* or *authenticator*
. *Verb* -- in the case of a Command, what we want the Subject to do.  In the case of an Event, what the Subject has done. For example, *authenticate* or *authenticated*.

These headers are filled in whenever a message is sent to the Headers Exchange, which routes the message to any interested parties.  Once the message arrives at its destination, the consumer needs to know what to do with the message.  That is where the Recipient List comes into play.  Each message payload contains a section which contains a list of message coordinates (header values) that need to be emitted.  Only *Command* types are in the list because each successful command implies an automatic generation of a companion event.  For example, a *user create* command will also cause a *user created* event to be emitted.

.Recipient List Section
[source,JSON]
----
{
    "recipient-list":
    [
        {
            "subject": "user",
            "verb": "create",
            "recipient-list" :
            [
                {
                    "subject": "images",
                    "verb": "create",
                    "recipient-list" : []
                }
            ]
        },
        {
            "subject": "sounds",
            "verb": "read",
            "recipient-list" :
            [
                {
                    "subject": "translation",
                    "verb": "read",
                    "recipient-list" : []
                }
            ]
        }
    ]
}
----

In the above example, there are two messages described in the sequence but notice that we are using a nested structure. The consumer will, concurrently, emit messages defined in the +recipient-list+ with the message headers containing the specified values.  The payload of the message will contain the values contained in the nested +recipient-list+, if any.  This structure gives the Operator the flexibility to create services that run serially and deep, concurrently and wide, or some combination of the two, depending on how deep the nesting goes.

=== Simulated Service Failure
We need the ability to have a service fail its health checks so that schedulers and altering systems can be tested.  The message payload contains a flag that tells the service to begin failing its health checks going forward.  That is to say, that this service invocation will succeed but from the health checks will begin to fail.

.Failed Health Checks Section
[source,JSON]
----
{
    "fail-health-checks": true
}
----

=== Simulated Service Latency
We need the ability to simulate latency in a service.  The message payload contains a list of integers that is used to constrain the range of randomized processing delays. The range is expressed as milliseconds. If set to 0, no latency is introduced and the service proceeds a quickly as possible.

.Latency Section
[source,JSON]
----
{
    "latency": {
        "minimum": 0,
        "maximum": 225
    }
}
----

=== Simulated Errors In Processing
No service is perfect and we need to see how the system behaves when errors occur.  The Operator can specify when errors occur by specifying a probability value from 0 (never fails) to 100 (always fails).  The resulting status code and message can also be specified.

.Failures Section
[source,JSON]
----
{
    "failures": {
        "probability": 75,
        "status-code" 1010,
        "status-message": "No such image."
    }
}
----


. Describe implementation details for important/complex parts of the system
. homegrown frameworks
. WebMVC frameworks
. approach to security
. domain model
. component frameworks
. configuration mechanisms
. architectural layering
. exceptions and logging
. how patterns and principals are implemented
. short description of each element using diagrams as necessary
. Technical people only

== Data
. Record anything that is important from the data perspective
. What does the data model look like?
. Where is data stored?
. Who owns the data?
. How much storage space is needed for the data?
. Are there any requirements for long term archival?
. Are there any requirements for log files and audit trails?
. Are flat files being used for storage?
. short description of each element using diagrams as necessary
. Technical people only, including Operations

== Infrastructure Architecture
. Describe the physical/virtual hardware and networks the software will be deployed to.
. Is there a clear physical architecture?
. What hardware does this include across all tiers?
. Does it cater for redundancy, failover and disaster recovery if applicable?
. Is it clear how the chosen hardware components have been sized and selected?
. If multiple servers and sites are used, what are the network links between them?
. Who is responsible for support and maintenance of the infrastructure?
. Are there central teams to look after common infrastructure?
. Who owns the resources?
. Are there sufficient environments for development, testing, acceptance, pre-production, production?
. Provide an infrastructure/network diagram with a short narrative
. Technical people only, including Operations

== Deployment
. Describe the mapping between software (containers) and the infrastructure.
. How and where is the software installed and configured?
. Is it clear how the software will be deployed across the infrastructure elements described in the Infrastructure Architecture section?
. What are the options and have they been documented?
. Is it understood how memory and CPU will be partitioned between the processes running on a single piece of infrastructure?
. Are any containers/components running in an active-active, active-passive, hot-standby, cold-standby formation?
. Has the deployment and rollback strategy been defined?
. What happens in the event of a software or infrastructure failure?
. Is it clear how data is replicated across sites?
. Can use tables to show mapping between containers and infrastructure
. Can use UML deployment diagrams
. Can use color coding to designate runtime status (primary vs secondary, etc_
. Technical people only, including Operations

== Operation and Support
. Be explicit about to run, monitor and manage the software
. Is it clear how the software provides the ability for Operations to monitor and manage the system?
. Has is this achieved across all tiers of the architecture?
. How can Operations diagnose problems?
. Where are errors and information logged?
. Do configuration changes require a restart?
. Are there any manual housekeeping tasks that need to be performed on a regular basis?
. Does old data need to be periodically archived?
. A simple narrative should suffice here
. Technical people only, including Operations

== Development Environment
. Summarize how new team members set up a development environment
. Pre-requisite versions of software needed
. Links to software downloads
. Links to virtual machines
. Environment variables
. Host name entries
. IDE configuration
. Build and test instructions
. Database population scripts
. Username, passwords and certificates for connecting to services
. Links to build servers
. Technical people only, developers specifically

== Decision Log
. Capture major decisions that have been made
. Why did you choose technology/framework X over Y and Z?
. How did you make the selection? PoC? Product evaluation?
. Did corporate policy or architecture standards force you to select X?
. Why did you choose the selected architecture?  What other options did you consider?
. How do you know that the solution satisfies the major non-functional requirements?
. Short paragraph describing each decision. Include a date of the decision?
. Technical people only
